{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9025703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_html_precise(filepath):\n",
    "    \"\"\"Enhanced HTML parsing with comprehensive financial data extraction\"\"\"\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        soup = BeautifulSoup(f, 'lxml')\n",
    "    \n",
    "    tables = soup.find_all('table')\n",
    "    print(f\"üîç Found {len(tables)} tables\")\n",
    "    \n",
    "    # Filter to likely financial tables\n",
    "    financial_tables = [t for t in tables if is_likely_financial_table(t)]\n",
    "    print(f\"üìä {len(financial_tables)} tables appear to contain financial data\")\n",
    "    \n",
    "    found = {key: 'N/A' for key in TARGET_VARIANTS.keys()}\n",
    "    match_details = {}  # Store matching details for debugging\n",
    "\n",
    "    # Remove empty or duplicate tables\n",
    "    unique_tables = []\n",
    "    seen_texts = set()\n",
    "    for table in financial_tables:\n",
    "        text = clean_text(table.get_text(\" \", strip=True))\n",
    "        if not text or text in seen_texts:\n",
    "            continue\n",
    "        seen_texts.add(text)\n",
    "        unique_tables.append(table)\n",
    "    financial_tables = unique_tables\n",
    "    \n",
    "    for table_idx, table in enumerate(financial_tables):\n",
    "        print(f\"üìã Processing table {table_idx + 1}\")\n",
    "        \n",
    "        # Check each target that hasn't been found yet\n",
    "        for target, variants in TARGET_VARIANTS.items():\n",
    "            if found[target] != 'N/A':\n",
    "                continue\n",
    "                \n",
    "            # Use hierarchical matching to find the best match in this table\n",
    "            value = find_hierarchical_matches(table, target, variants)\n",
    "\n",
    "            if value is None:\n",
    "                value = find_vertical_match(table, target, variants)\n",
    "\n",
    "            if value is not None:\n",
    "                found[target] = value\n",
    "                match_details[target] = {\n",
    "                    'table': table_idx + 1,\n",
    "                    'value': value\n",
    "                }\n",
    "                print(f\"‚úÖ Found {target}: {value}\")\n",
    "\n",
    "    \n",
    "    # Compute derived values\n",
    "    try:\n",
    "        if found['Total Debt'] == 'N/A':\n",
    "            short_debt = found.get(\"Short-Term Debt\", 0) if found.get(\"Short-Term Debt\") != 'N/A' else 0\n",
    "            long_debt = found.get(\"Long-Term Debt\", 0) if found.get(\"Long-Term Debt\") != 'N/A' else 0\n",
    "            if short_debt != 0 or long_debt != 0:\n",
    "                found[\"Total Debt\"] = float(short_debt) + float(long_debt)\n",
    "                print(f\"üìä Calculated Total Debt: {found['Total Debt']}\")\n",
    "                \n",
    "        # Calculate Free Cash Flow if not found\n",
    "        if found['Free Cash Flow'] == 'N/A':\n",
    "            ocf = found.get(\"Operating Cash Flow\", 0) if found.get(\"Operating Cash Flow\") != 'N/A' else 0\n",
    "            capex = found.get(\"Capital Expenditures (CapEx)\", 0) if found.get(\"Capital Expenditures (CapEx)\") != 'N/A' else 0\n",
    "            if ocf != 0 and capex != 0:\n",
    "                found[\"Free Cash Flow\"] = float(ocf) - abs(float(capex))  # CapEx is usually negative\n",
    "                print(f\"üìä Calculated Free Cash Flow: {found['Free Cash Flow']}\")\n",
    "                \n",
    "        # Calculate Gross Profit if not found\n",
    "        if found['Gross Profit'] == 'N/A':\n",
    "            revenue = found.get(\"Revenue\", 0) if found.get(\"Revenue\") != 'N/A' else 0\n",
    "            cost_of_revenue = found.get(\"Cost of Revenue\", 0) if found.get(\"Cost of Revenue\") != 'N/A' else 0\n",
    "            if revenue != 0 and cost_of_revenue != 0:\n",
    "                found[\"Gross Profit\"] = float(revenue) - float(cost_of_revenue)\n",
    "                print(f\"üìä Calculated Gross Profit: {found['Gross Profit']}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error in calculations: {e}\")\n",
    "    \n",
    "    # Print summary of what was found\n",
    "    found_count = sum(1 for v in found.values() if v != 'N/A')\n",
    "    print(f\"\\nüìà Extracted {found_count}/{len(TARGET_VARIANTS)} financial metrics\")\n",
    "    \n",
    "    return found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b6abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_tickers():\n",
    "    cik_df = get_cik_mapping()\n",
    "    all_data = []\n",
    "\n",
    "    for ticker in TICKERS:\n",
    "        print(f\"\\nüìä Processing {ticker}\")\n",
    "        try:\n",
    "            cik, company = find_cik(ticker, cik_df)\n",
    "            if not cik:\n",
    "                print(f\"‚ùå No CIK for {ticker}\")\n",
    "                continue\n",
    "            content, form, date = download_latest_filing(cik)\n",
    "            path = save_filing(content, ticker, form, date)\n",
    "            data = parse_html_precise(path)\n",
    "\n",
    "            record = {\"Company\": company, \"Ticker\": ticker, \"Filing Date\": date, \"Filing Type\": form}\n",
    "            record.update(data)\n",
    "            all_data.append(record)\n",
    "            time.sleep(1)  # respectful delay\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error for {ticker}: {e}\")\n",
    "\n",
    "    if all_data:\n",
    "        df = pd.DataFrame(all_data)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        file = os.path.join(DOWNLOAD_DIR, f\"financials_{timestamp}.xlsx\")\n",
    "        df.to_excel(file, index=False)\n",
    "        print(f\"\\n‚úÖ All data saved to: {file}\")\n",
    "        \n",
    "        # Print comprehensive summary of what was found\n",
    "        print(\"\\nüìà Comprehensive Extraction Summary:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Group by category\n",
    "        categories = {\n",
    "            \"Balance Sheet - Assets\": [\"Current Assets\", \"Total Assets\", \"Goodwill\", \"Intangible Assets\", \n",
    "                                     \"Property, Plant, and Equipment (Net)\", \"Cash and Cash Equivalents\", \n",
    "                                     \"Accounts Receivable\", \"Inventory\"],\n",
    "            \"Balance Sheet - Liabilities\": [\"Current Liabilities\", \"Total Liabilities\", \"Short-Term Debt\", \n",
    "                                          \"Long-Term Debt\", \"Total Debt\", \"Accounts Payable\"],\n",
    "            \"Balance Sheet - Equity\": [\"Total Equity\", \"Treasury Stock\", \"Retained Earnings\", \"Preferred Stock\", \n",
    "                                     \"Common Shares Outstanding\", \"Book Value of Equity\", \n",
    "                                     \"Accumulated Other Comprehensive Income\"],\n",
    "            \"Income Statement\": [\"Revenue\", \"Net Income\", \"Operating Income (EBIT)\", \"Income Before Tax\", \n",
    "                               \"Income Tax Expense\", \"Research and Development Expense\", \"Cost of Revenue\", \n",
    "                               \"Gross Profit\", \"Comprehensive Income\"],\n",
    "            \"Cash Flow Statement\": [\"Operating Cash Flow\", \"Capital Expenditures (CapEx)\", \n",
    "                                  \"Depreciation & Amortization\", \"Free Cash Flow\"]\n",
    "        }\n",
    "        \n",
    "        for category, fields in categories.items():\n",
    "            print(f\"\\n{category}:\")\n",
    "            found_in_category = 0\n",
    "            for field in fields:\n",
    "                if field in TARGET_VARIANTS:\n",
    "                    found_count = sum(1 for row in all_data if row.get(field) != 'N/A')\n",
    "                    status = \"‚úÖ\" if found_count > 0 else \"‚ùå\"\n",
    "                    print(f\"  {status} {field}: {found_count}/{len(all_data)} companies\")\n",
    "                    if found_count > 0:\n",
    "                        found_in_category += 1\n",
    "            print(f\"  üìä Category Success: {found_in_category}/{len(fields)} fields found\")\n",
    "        \n",
    "        # Overall statistics\n",
    "        total_possible = len(TARGET_VARIANTS) * len(all_data)\n",
    "        total_found = sum(1 for row in all_data for key in TARGET_VARIANTS.keys() if row.get(key) != 'N/A')\n",
    "        success_rate = (total_found / total_possible) * 100\n",
    "        print(f\"\\nüéØ Overall Success Rate: {success_rate:.1f}% ({total_found}/{total_possible} data points)\")\n",
    "        \n",
    "        # Show companies with most/least data\n",
    "        company_scores = []\n",
    "        for row in all_data:\n",
    "            found_count = sum(1 for key in TARGET_VARIANTS.keys() if row.get(key) != 'N/A')\n",
    "            company_scores.append((row['Company'], found_count))\n",
    "        \n",
    "        company_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        print(f\"\\nüèÜ Data Coverage by Company:\")\n",
    "        for company, count in company_scores:\n",
    "            percentage = (count / len(TARGET_VARIANTS)) * 100\n",
    "            print(f\"  {company}: {count}/{len(TARGET_VARIANTS)} ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(\"=\" * 50)\n",
    "    else:\n",
    "        print(\"‚ùå No data extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be39e54",
   "metadata": {},
   "source": [
    "Appending the data to final excel sheet and saving the file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6258f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Append to Excel Master Sheet ===\n",
    "def append_to_master_excel(new_data, output_file):\n",
    "    new_df = pd.DataFrame(new_data)\n",
    "    if os.path.exists(output_file):\n",
    "        existing_df = pd.read_excel(output_file)\n",
    "        combined_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "    else:\n",
    "        combined_df = new_df\n",
    "    combined_df.to_excel(output_file, index=False)\n",
    "    print(f\"\\n‚úÖ Data appended to: {output_file}\")\n",
    "\n",
    "# === Processing Logic ===\n",
    "def process_all_tickers():\n",
    "    cik_df = get_cik_mapping()\n",
    "    all_data = []\n",
    "\n",
    "    for ticker in TICKERS:\n",
    "        print(f\"\\nüìä Processing {ticker}\")\n",
    "        try:\n",
    "            cik, company = find_cik(ticker, cik_df)\n",
    "            if not cik:\n",
    "                continue\n",
    "            content, form, date = download_latest_filing(cik)\n",
    "            path = save_filing(content, ticker, form, date)\n",
    "            data = parse_html_precise(path)\n",
    "\n",
    "            record = {\"Company\": company, \"Ticker\": ticker, \"Filing Date\": date, \"Filing Type\": form}\n",
    "            record.update(data)\n",
    "            all_data.append(record)\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error for {ticker}: {e}\")\n",
    "\n",
    "    if all_data:\n",
    "        append_to_master_excel(all_data, OUTPUT_FILE)\n",
    "\n",
    "# === MAIN ===\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Starting financial data extraction\")\n",
    "    process_all_tickers()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantproenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
