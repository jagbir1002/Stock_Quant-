{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fef9ef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad569d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION ===\n",
    "TICKER_SOURCE_PATH = r\"C:\\Users\\surji\\Desktop\\Quant_Poject\\CompanyList_File_Tickers.xlsx\"\n",
    "DOWNLOAD_DIR = r\"C:\\Users\\surji\\Desktop\\Quant_Poject\\Downloaded Filings\"\n",
    "TICKER_COLUMN = \"Ticker\"  # Column name in Excel with tickers\n",
    "OUTPUT_FILE = os.path.join(DOWNLOAD_DIR, \"Parsed_DATA.xlsx\")\n",
    "USER_AGENT = \"MyAppName your_email@example.com\"\n",
    "\n",
    "# === Read tickers from Excel ===\n",
    "def read_tickers_from_excel(path, column_name):\n",
    "    df = pd.read_excel(path)\n",
    "    return df[column_name].dropna().unique().tolist()\n",
    "\n",
    "TICKERS = read_tickers_from_excel(TICKER_SOURCE_PATH, TICKER_COLUMN)\n",
    "\n",
    "# === Ensure download directory exists ===\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# === COMPREHENSIVE TARGET_VARIANTS WITH IMPROVED MATCHING ===\n",
    "TARGET_VARIANTS = {\n",
    "    # Assets\n",
    "    \"Current Assets\": [\n",
    "        \"current assets\", \"total current assets\", \"current assets total\"\n",
    "    ],\n",
    "    \"Non-Current Assets\": [\n",
    "        \"non-current assets\", \"non current assets\", \"long-term assets\", \"long term assets\",\n",
    "        \"noncurrent assets\", \"total non-current assets\", \"total long-term assets\", \n",
    "        \"total long term assets\", \"total noncurrent assets\"\n",
    "    ],\n",
    "    \"Total Assets\": [\n",
    "        \"total assets\", \"assets total\", \"total consolidated assets\"\n",
    "    ],\n",
    "    \"Cash and Cash Equivalents\": [\n",
    "        \"cash and cash equivalents\", \"cash and equivalents\", \"cash & cash equivalents\",\n",
    "        \"cash, cash equivalents, and short-term investments\",\n",
    "        \"cash, cash equivalents and short-term investments\",\n",
    "        \"cash and short-term investments\", \"cash & short-term investments\"\n",
    "    ],\n",
    "    \"Property, Plant, and Equipment (Net)\": [\n",
    "        \"property and equipment, net\", \"property, plant and equipment, net\",\n",
    "        \"property, plant & equipment, net\", \"property plant and equipment net\",\n",
    "        \"pp&e\", \"ppe\", \"property and equipment net\", \"plant and equipment net\",\n",
    "        \"property plant equipment net\", \"fixed assets net\"\n",
    "    ],\n",
    "    \"Goodwill\": [\n",
    "        \"goodwill\", \"goodwill net\", \"goodwill and intangible assets\"\n",
    "    ],\n",
    "    \"Intangible Assets\": [\n",
    "        \"intangible assets, net\", \"intangible assets net\", \"other intangible assets\",\n",
    "        \"acquired intangible assets\", \"intangible assets\", \"intangibles net\"\n",
    "    ],\n",
    "    \"Accounts Receivable\": [\n",
    "        \"accounts receivable\", \"accounts receivable net\", \"trade receivables\", \n",
    "        \"receivables\", \"trade and other receivables\", \"accounts receivable, net\"\n",
    "    ],\n",
    "    \"Inventory\": [\n",
    "        \"inventory\", \"inventories\", \"finished goods\", \"raw materials\",\n",
    "        \"inventory net\", \"total inventory\"\n",
    "    ],\n",
    "\n",
    "    # Liabilities\n",
    "    \"Current Liabilities\": [\n",
    "        \"current liabilities\", \"total current liabilities\", \"current liabilities total\"\n",
    "    ],\n",
    "    \"Non-Current Liabilities\": [\n",
    "        \"non-current liabilities\", \"non current liabilities\", \"long term liabilities\",\n",
    "        \"noncurrent liabilities\", \"total non-current liabilities\", \n",
    "        \"total long-term liabilities\", \"other long-term liabilities\",\n",
    "        \"long-term liabilities\", \"total noncurrent liabilities\"\n",
    "    ],\n",
    "    \"Total Liabilities\": [\n",
    "        \"total liabilities\", \"liabilities total\", \"total consolidated liabilities\"\n",
    "    ],\n",
    "    \"Short-Term Debt\": [\n",
    "        \"short-term debt\", \"short term debt\", \"current portion of long-term debt\",\n",
    "        \"current debt\", \"current borrowings\", \"short-term borrowings\",\n",
    "        \"current portion of debt\", \"debt due within one year\"\n",
    "    ],\n",
    "    \"Long-Term Debt\": [\n",
    "        \"long-term debt\", \"long term debt\", \"long-term borrowings\",\n",
    "        \"long-term obligations\", \"noncurrent debt\", \"debt securities\",\n",
    "        \"long-term debt securities\", \"term debt\"\n",
    "    ],\n",
    "    \"Accounts Payable\": [\n",
    "        \"accounts payable\", \"trade payables\", \"accounts payable and accrued liabilities\",\n",
    "        \"trade and other payables\"\n",
    "    ],\n",
    "    \"Total Debt\": [\n",
    "        \"total debt\", \"total borrowings\", \"total debt securities\"\n",
    "    ],\n",
    "\n",
    "    # Equity\n",
    "    \"Total Equity\": [\n",
    "        \"total stockholders' equity\", \"total shareholders' equity\", \"total equity\",\n",
    "        \"stockholders' equity\", \"shareholders' equity\", \"total shareholders equity\",\n",
    "        \"total stockholders equity\", \"stockholders equity\", \"shareholders equity\"\n",
    "    ],\n",
    "    \"Treasury Stock\": [\n",
    "        \"treasury stock\", \"treasury shares\", \"shares held in treasury\"\n",
    "    ],\n",
    "    \"Retained Earnings\": [\n",
    "        \"retained earnings\", \"accumulated deficit\", \"accumulated earnings\",\n",
    "        \"retained earnings (accumulated deficit)\"\n",
    "    ],\n",
    "    \"Preferred Stock\": [\n",
    "        \"preferred stock\", \"preference shares\", \"preferred shares\"\n",
    "    ],\n",
    "    \"Common Shares Outstanding\": [\n",
    "        \"common shares outstanding\", \"common stock outstanding\", \"ordinary shares outstanding\",\n",
    "        \"common stock and paid-in capital\", \"common stock\", \"ordinary shares\"\n",
    "    ],\n",
    "    \"Book Value of Equity\": [\n",
    "        \"book value of equity\", \"stockholders equity\", \"net worth\"\n",
    "    ],\n",
    "    \"Accumulated Other Comprehensive Income\": [\n",
    "        \"accumulated other comprehensive income\", \"accumulated other comprehensive loss\",\n",
    "        \"accumulated other comprehensive income (loss)\", \"aoci\"\n",
    "    ],\n",
    "\n",
    "    # Income Statement\n",
    "    \"Revenue\": [\n",
    "        \"total revenue\", \"revenue\", \"net revenue\", \"net sales\", \"total net sales\",\n",
    "        \"sales\", \"total sales\", \"operating revenue\", \"service revenue\"\n",
    "    ],\n",
    "    \"Cost of Revenue\": [\n",
    "        \"cost of revenue\", \"cost of sales\", \"cost of goods sold\", \"cogs\",\n",
    "        \"cost of services\", \"cost of products sold\"\n",
    "    ],\n",
    "    \"Gross Profit\": [\n",
    "        \"gross margin\", \"gross profit\", \"gross income\"\n",
    "    ],\n",
    "    \"Operating Income (EBIT)\": [\n",
    "        \"operating income\", \"income from operations\", \"operating profit\",\n",
    "        \"earnings before interest and taxes\", \"ebit\", \"operating earnings\"\n",
    "    ],\n",
    "    \"Net Income\": [\n",
    "        \"net income\", \"net earnings\", \"net income (loss)\", \"net profit\",\n",
    "        \"profit for the year\", \"profit attributable to shareholders\"\n",
    "    ],\n",
    "    \"Research and Development Expense\": [\n",
    "        \"research and development\", \"r&d expense\", \"research and development expense\",\n",
    "        \"research and development costs\"\n",
    "    ],\n",
    "    \"Income Before Tax\": [\n",
    "        \"income before income taxes\", \"income before tax\", \"earnings before tax\",\n",
    "        \"profit before tax\", \"income before provision for income taxes\"\n",
    "    ],\n",
    "    \"Income Tax Expense\": [\n",
    "        \"provision for income taxes\", \"income tax expense\", \"income taxes\",\n",
    "        \"tax expense\", \"income tax provision\"\n",
    "    ],\n",
    "    \"Comprehensive Income\": [\n",
    "        \"comprehensive income\", \"total comprehensive income\", \"comprehensive earnings\"\n",
    "    ],\n",
    "\n",
    "    # Cash Flow\n",
    "    \"Operating Cash Flow\": [\n",
    "        \"net cash from operations\", \"net cash provided by operating activities\",\n",
    "        \"operating cash flow\", \"cash flows from operating activities\",\n",
    "        \"net cash from operating activities\"\n",
    "    ],\n",
    "    \"Capital Expenditures (CapEx)\": [\n",
    "        \"additions to property and equipment\", \"purchases of property and equipment\",\n",
    "        \"capital expenditures\", \"capex\", \"capital investments\", \"capital additions\"\n",
    "    ],\n",
    "    \"Depreciation & Amortization\": [\n",
    "        \"depreciation, amortization, and other\", \"depreciation and amortization\",\n",
    "        \"amortization\", \"depreciation\", \"depreciation expense\"\n",
    "    ],\n",
    "    \"Free Cash Flow\": [\n",
    "        \"free cash flow\", \"cash flow from operations less capex\"\n",
    "    ],\n",
    "    \"NOPAT\": [\n",
    "        \"nopat\", \"net operating profit after tax\", \"net operating profit\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# === EXCLUSION PATTERNS TO AVOID WRONG MATCHES ===\n",
    "EXCLUSION_PATTERNS = {\n",
    "    \"Total Assets\": [\"deferred tax assets\", \"other assets\", \"current assets\", \"non-current assets\"],\n",
    "    \"Total Liabilities\": [\"deferred tax liabilities\", \"other liabilities\", \"current liabilities\", \"non-current liabilities\"],\n",
    "    \"Total Equity\": [\"stockholders' deficit\", \"shareholders' deficit\", \"equity method\"],\n",
    "    \"Revenue\": [\"deferred revenue\", \"unearned revenue\", \"other revenue\"],\n",
    "    \"Net Income\": [\"other comprehensive income\", \"loss\", \"deficit\"],\n",
    "    \"Operating Income (EBIT)\": [\"non-operating income\", \"other income\"],\n",
    "    \"Cash and Cash Equivalents\": [\"restricted cash\", \"cash flows\"],\n",
    "    \"Current Assets\": [\"non-current assets\", \"total assets\"],\n",
    "    \"Current Liabilities\": [\"non-current liabilities\", \"total liabilities\"],\n",
    "    \"Short-Term Debt\": [\"long-term debt\", \"total debt\"],\n",
    "    \"Long-Term Debt\": [\"short-term debt\", \"current portion\"],\n",
    "    \"Comprehensive Income\": [\"other comprehensive income\", \"accumulated other comprehensive\"]\n",
    "}\n",
    "\n",
    "# === Ensure download directory exists ===\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# === Helper functions ===\n",
    "def get_cik_mapping():\n",
    "    url = \"https://www.sec.gov/files/company_tickers.json\"\n",
    "    resp = requests.get(url, headers={'User-Agent': USER_AGENT})\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    df = pd.DataFrame.from_dict(data, orient='index')\n",
    "    df['ticker'] = df['ticker'].str.upper()\n",
    "    df['cik_str'] = df['cik_str'].apply(lambda x: str(x).zfill(10))\n",
    "    return df\n",
    "\n",
    "def find_cik(ticker, cik_df):\n",
    "    ticker_norm = ticker.replace('.', '-').upper()\n",
    "    row = cik_df[cik_df['ticker'] == ticker_norm]\n",
    "    if not row.empty:\n",
    "        return row.iloc[0]['cik_str'], row.iloc[0]['title']\n",
    "\n",
    "    row = cik_df[cik_df['ticker'] == ticker.upper()]\n",
    "    if not row.empty:\n",
    "        return row.iloc[0]['cik_str'], row.iloc[0]['title']\n",
    "\n",
    "    # Fallback: fuzzy match by prefix\n",
    "    partial_matches = cik_df[cik_df['ticker'].str.startswith(ticker.split('.')[0].upper())]\n",
    "    if not partial_matches.empty:\n",
    "        best_row = partial_matches.iloc[0]\n",
    "        print(f\"\\u26a0\\ufe0f Auto-fallback matched '{ticker}' ‚Üí '{best_row['ticker']}' ({best_row['title']})\")\n",
    "        return best_row['cik_str'], best_row['title']\n",
    "\n",
    "    print(f\"\\u274c No CIK for {ticker}\")\n",
    "    return None, None\n",
    "\n",
    "def download_latest_filing(cik):\n",
    "    url = f\"https://data.sec.gov/submissions/CIK{cik}.json\"\n",
    "    resp = requests.get(url, headers={'User-Agent': USER_AGENT})\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    filings = data['filings']['recent']\n",
    "    \n",
    "    form_priority = ['10-K', '20-F', '10-Q', '6-K']  # Priority order\n",
    "\n",
    "    for form_type in form_priority:\n",
    "        for i in range(len(filings['form'])):\n",
    "            form = filings['form'][i]\n",
    "            if form == form_type:\n",
    "                accession = filings['accessionNumber'][i].replace('-', '')\n",
    "                doc = filings['primaryDocument'][i]\n",
    "                filing_date = filings['filingDate'][i]\n",
    "                file_url = f\"https://www.sec.gov/Archives/edgar/data/{int(cik)}/{accession}/{doc}\"\n",
    "                print(f\"üì• Downloading {form} on {filing_date}\")\n",
    "                r = requests.get(file_url, headers={'User-Agent': USER_AGENT})\n",
    "                r.raise_for_status()\n",
    "                return r.text, form, filing_date\n",
    "    raise Exception(\"No suitable filing found\")\n",
    "\n",
    "\n",
    "def save_filing(content, ticker, form, date):\n",
    "    filename = f\"{ticker}_{form}_{date.replace('-', '')}.html\"\n",
    "    path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "    return path\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Enhanced text cleaning\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    # Remove common HTML entities and normalize whitespace\n",
    "    text = text.replace('\\xa0', ' ').replace('\\n', ' ').replace('\\t', ' ')\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Multiple spaces to single space\n",
    "    text = text.strip().lower()\n",
    "    # Remove common prefixes/suffixes that might interfere\n",
    "    text = re.sub(r'^\\$\\s*', '', text)  # Remove leading $\n",
    "    text = re.sub(r'\\s*\\$\\s*$', '', text)  # Remove trailing $\n",
    "    return text\n",
    "\n",
    "def extract_numeric(text):\n",
    "    \"\"\"Enhanced numeric extraction with better handling of negative numbers and formats\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    \n",
    "    # Clean the text first\n",
    "    text = text.replace(',', '').replace('$', '')\n",
    "    \n",
    "    # Handle parentheses as negative (accounting format)\n",
    "    if '(' in text and ')' in text:\n",
    "        text = text.replace('(', '-').replace(')', '')\n",
    "    \n",
    "    # Find all numbers including decimals and negatives\n",
    "    matches = re.findall(r'-?\\d+(?:\\.\\d+)?', text)\n",
    "    \n",
    "    if matches:\n",
    "        try:\n",
    "            return float(matches[0])\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def is_likely_financial_table(table):\n",
    "    \"\"\"Check if table is likely to contain financial data\"\"\"\n",
    "    text = table.get_text().lower()\n",
    "    financial_indicators = [\n",
    "        'assets', 'liabilities', 'equity', 'income', 'revenue', 'cash',\n",
    "        'debt', 'current', 'total', 'million', 'thousand', '$'\n",
    "    ]\n",
    "    return sum(indicator in text for indicator in financial_indicators) >= 3\n",
    "\n",
    "def should_exclude_match(target, cell_text, matched_variant):\n",
    "    \"\"\"Check if a match should be excluded based on exclusion patterns\"\"\"\n",
    "    if target not in EXCLUSION_PATTERNS:\n",
    "        return False\n",
    "    \n",
    "    exclusion_patterns = EXCLUSION_PATTERNS[target]\n",
    "    \n",
    "    # Check if any exclusion pattern is found in the cell text\n",
    "    for pattern in exclusion_patterns:\n",
    "        if pattern.lower() in cell_text.lower():\n",
    "            print(f\"üö´ Excluding '{cell_text}' for {target} (matches exclusion pattern: '{pattern}')\")\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def calculate_match_score(cell_text, variant, target):\n",
    "    \"\"\"Enhanced scoring system that prioritizes specificity and completeness\"\"\"\n",
    "    cell_text = cell_text.lower().strip()\n",
    "    variant = variant.lower().strip()\n",
    "    \n",
    "    # Perfect exact match\n",
    "    if cell_text == variant:\n",
    "        return 100\n",
    "    \n",
    "    # Check for exclusion patterns first\n",
    "    if should_exclude_match(target, cell_text, variant):\n",
    "        return 0\n",
    "    \n",
    "    # Penalize matches that are too generic compared to what we want\n",
    "    # For example, if looking for \"comprehensive income\" but finding \"other comprehensive income\"\n",
    "    if len(variant.split()) > 1:  # Multi-word targets\n",
    "        variant_words = set(variant.split())\n",
    "        cell_words = set(cell_text.split())\n",
    "        \n",
    "        # If cell has extra words that might make it more specific (and wrong)\n",
    "        extra_words = cell_words - variant_words\n",
    "        if extra_words:\n",
    "            # Common words that make items more specific (and often wrong for totals)\n",
    "            specificity_words = {'other', 'foreign', 'unrealized', 'current', 'non-current', 'noncurrent'}\n",
    "            if extra_words.intersection(specificity_words):\n",
    "                return 0  # Reject overly specific matches\n",
    "    \n",
    "    # Enhanced scoring based on different match types\n",
    "    if variant in cell_text:\n",
    "        # Variant is completely contained in cell text\n",
    "        coverage_ratio = len(variant) / len(cell_text)\n",
    "        base_score = 85 * coverage_ratio\n",
    "        \n",
    "        # Bonus for being at the start or end (often indicates it's a main item)\n",
    "        if cell_text.startswith(variant) or cell_text.endswith(variant):\n",
    "            base_score += 10\n",
    "            \n",
    "        return min(base_score, 95)  # Cap at 95 to reserve 100 for exact matches\n",
    "    \n",
    "    elif cell_text in variant:\n",
    "        # Cell text is contained in variant (less ideal but acceptable)\n",
    "        coverage_ratio = len(cell_text) / len(variant)\n",
    "        return 70 * coverage_ratio\n",
    "    \n",
    "    # Fuzzy matching for similar words\n",
    "    variant_words = set(variant.split())\n",
    "    cell_words = set(cell_text.split())\n",
    "    \n",
    "    # Calculate word overlap\n",
    "    common_words = variant_words.intersection(cell_words)\n",
    "    if common_words:\n",
    "        word_match_ratio = len(common_words) / len(variant_words)\n",
    "        return 60 * word_match_ratio\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def find_best_match_in_row(row_cells, target_variants, target_name):\n",
    "    \"\"\"Find the best matching cell for target variants with improved scoring\"\"\"\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    best_variant = None\n",
    "    \n",
    "    for i, cell in enumerate(row_cells):\n",
    "        cell_text = clean_text(cell.get_text(\" \", strip=True))\n",
    "        \n",
    "        # Skip empty cells\n",
    "        if not cell_text:\n",
    "            continue\n",
    "        \n",
    "        # Try each variant\n",
    "        for variant in target_variants:\n",
    "            score = calculate_match_score(cell_text, variant, target_name)\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = i\n",
    "                best_variant = variant\n",
    "    \n",
    "    return best_match, best_score, best_variant\n",
    "\n",
    "def extract_value_from_row(row_cells, label_cell_index):\n",
    "    \"\"\"Extract numeric value from row, prioritizing right-aligned cells, then others.\"\"\"\n",
    "    # Try scanning right-side first\n",
    "    for i in range(label_cell_index + 1, len(row_cells)):\n",
    "        text = clean_text(row_cells[i].get_text(\" \", strip=True))\n",
    "        value = extract_numeric(text)\n",
    "        if value is not None:\n",
    "            return value\n",
    "\n",
    "    # Then try all numeric-looking cells\n",
    "    for i, cell in enumerate(row_cells):\n",
    "        if i == label_cell_index:\n",
    "            continue\n",
    "        text = clean_text(cell.get_text(\" \", strip=True))\n",
    "        if re.search(r'[\\d\\)$]', text):  # heuristic for financial numbers\n",
    "            value = extract_numeric(text)\n",
    "            if value is not None:\n",
    "                return value\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_hierarchical_matches(table, target, variants):\n",
    "    \"\"\"Finds best label match and corresponding value in a table.\"\"\"\n",
    "    rows = table.find_all('tr')\n",
    "    matches = []\n",
    "\n",
    "    for row_idx, row in enumerate(rows):\n",
    "        cells = row.find_all(['td', 'th'])\n",
    "        if len(cells) < 2:\n",
    "            continue\n",
    "\n",
    "        # Clean and standardize row text\n",
    "        cell_texts = [clean_text(c.get_text(\" \", strip=True)) for c in cells]\n",
    "\n",
    "        # Avoid subtotal rows like \"Total current liabilities (continued)\"\n",
    "        row_text_combined = \" \".join(cell_texts)\n",
    "        if any(term in row_text_combined for term in ['continued', 'schedule', 'note']):\n",
    "            continue\n",
    "\n",
    "        match_index, score, matched_variant = find_best_match_in_row(cells, variants, target)\n",
    "\n",
    "        if match_index is not None and score >= 60:\n",
    "            value = extract_value_from_row(cells, match_index)\n",
    "            if value is not None:\n",
    "                matches.append({\n",
    "                    'row_idx': row_idx,\n",
    "                    'score': score,\n",
    "                    'value': value,\n",
    "                    'label': cells[match_index].get_text(\" \", strip=True),\n",
    "                    'variant': matched_variant\n",
    "                })\n",
    "\n",
    "    if not matches:\n",
    "        return None\n",
    "\n",
    "    # Sort by score then row position\n",
    "    matches.sort(key=lambda x: (x['score'], x['row_idx']), reverse=True)\n",
    "    best = matches[0]\n",
    "    print(f\"üéØ Best match for {target}: {best['value']} | Label: {best['label']} | Score: {best['score']:.1f}\")\n",
    "    return best['value']\n",
    "\n",
    "def find_vertical_match(table, target, variants):\n",
    "    \"\"\"Find best match in table scanning vertically, targeting US$ column only and avoiding percentage columns like 100%.\"\"\"\n",
    "    rows = table.find_all('tr')\n",
    "    if len(rows) < 2:\n",
    "        return None\n",
    "\n",
    "    # Build clean grid\n",
    "    grid = []\n",
    "    for row in rows:\n",
    "        cells = row.find_all(['td', 'th'])\n",
    "        grid.append([clean_text(cell.get_text(\" \", strip=True)) for cell in cells])\n",
    "\n",
    "    num_rows = len(grid)\n",
    "    num_cols = max(len(row) for row in grid)\n",
    "    for row in grid:\n",
    "        while len(row) < num_cols:\n",
    "            row.append(\"\")\n",
    "\n",
    "    # Step 1: Identify US$ column(s) ‚Äî columns that have 'US$' but not 'percentage'\n",
    "    usd_col_indices = []\n",
    "    for col_idx in range(num_cols):\n",
    "        col_text_top = \" \".join([grid[i][col_idx] for i in range(min(3, num_rows))])\n",
    "        if any(curr in col_text_top for curr in [\"us$\", \"usd\", \"$\"]) and \"percentage\" not in col_text_top:\n",
    "            usd_col_indices.append(col_idx)\n",
    "\n",
    "    if not usd_col_indices:\n",
    "        return None\n",
    "\n",
    "    # Step 2: Search each row for label match and return value from the US$ column\n",
    "    best_value = None\n",
    "    best_score = 0\n",
    "    for row in grid:\n",
    "        for label_idx, cell_text in enumerate(row):\n",
    "            for variant in variants:\n",
    "                score = calculate_match_score(cell_text, variant, target)\n",
    "                if score > best_score:\n",
    "                    for usd_col in usd_col_indices:\n",
    "                        if usd_col < len(row):\n",
    "                            candidate = row[usd_col]\n",
    "                            if \"%\" in candidate or \"percentage\" in candidate.lower():\n",
    "                                continue\n",
    "                            value = extract_numeric(candidate)\n",
    "                            if value is not None and value > 100:  # avoid matching percentages\n",
    "                                best_value = value\n",
    "                                best_score = score\n",
    "\n",
    "    if best_value is not None:\n",
    "        print(f\"üìà US$ vertical match for {target}: {best_value}\")\n",
    "    return best_value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_html_precise(filepath):\n",
    "    \"\"\"Enhanced HTML parsing with comprehensive financial data extraction\"\"\"\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        soup = BeautifulSoup(f, 'lxml')\n",
    "    \n",
    "    tables = soup.find_all('table')\n",
    "    print(f\"üîç Found {len(tables)} tables\")\n",
    "    \n",
    "    # Filter to likely financial tables\n",
    "    financial_tables = [t for t in tables if is_likely_financial_table(t)]\n",
    "    print(f\"üìä {len(financial_tables)} tables appear to contain financial data\")\n",
    "    \n",
    "    found = {key: 'N/A' for key in TARGET_VARIANTS.keys()}\n",
    "    match_details = {}  # Store matching details for debugging\n",
    "\n",
    "    # Remove empty or duplicate tables\n",
    "    unique_tables = []\n",
    "    seen_texts = set()\n",
    "    for table in financial_tables:\n",
    "        text = clean_text(table.get_text(\" \", strip=True))\n",
    "        if not text or text in seen_texts:\n",
    "            continue\n",
    "        seen_texts.add(text)\n",
    "        unique_tables.append(table)\n",
    "    financial_tables = unique_tables\n",
    "    \n",
    "    for table_idx, table in enumerate(financial_tables):\n",
    "        print(f\"üìã Processing table {table_idx + 1}\")\n",
    "        \n",
    "        # Check each target that hasn't been found yet\n",
    "        for target, variants in TARGET_VARIANTS.items():\n",
    "            if found[target] != 'N/A':\n",
    "                continue\n",
    "                \n",
    "            # Use hierarchical matching to find the best match in this table\n",
    "            value = find_hierarchical_matches(table, target, variants)\n",
    "\n",
    "            if value is None:\n",
    "                value = find_vertical_match(table, target, variants)\n",
    "\n",
    "            if value is not None:\n",
    "                found[target] = value\n",
    "                match_details[target] = {\n",
    "                    'table': table_idx + 1,\n",
    "                    'value': value\n",
    "                }\n",
    "                print(f\"‚úÖ Found {target}: {value}\")\n",
    "\n",
    "    \n",
    "    # Compute derived values\n",
    "    try:\n",
    "        if found['Total Debt'] == 'N/A':\n",
    "            short_debt = found.get(\"Short-Term Debt\", 0) if found.get(\"Short-Term Debt\") != 'N/A' else 0\n",
    "            long_debt = found.get(\"Long-Term Debt\", 0) if found.get(\"Long-Term Debt\") != 'N/A' else 0\n",
    "            if short_debt != 0 or long_debt != 0:\n",
    "                found[\"Total Debt\"] = float(short_debt) + float(long_debt)\n",
    "                print(f\"üìä Calculated Total Debt: {found['Total Debt']}\")\n",
    "                \n",
    "        # Calculate Free Cash Flow if not found\n",
    "        if found['Free Cash Flow'] == 'N/A':\n",
    "            ocf = found.get(\"Operating Cash Flow\", 0) if found.get(\"Operating Cash Flow\") != 'N/A' else 0\n",
    "            capex = found.get(\"Capital Expenditures (CapEx)\", 0) if found.get(\"Capital Expenditures (CapEx)\") != 'N/A' else 0\n",
    "            if ocf != 0 and capex != 0:\n",
    "                found[\"Free Cash Flow\"] = float(ocf) - abs(float(capex))  # CapEx is usually negative\n",
    "                print(f\"üìä Calculated Free Cash Flow: {found['Free Cash Flow']}\")\n",
    "                \n",
    "        # Calculate Gross Profit if not found\n",
    "        if found['Gross Profit'] == 'N/A':\n",
    "            revenue = found.get(\"Revenue\", 0) if found.get(\"Revenue\") != 'N/A' else 0\n",
    "            cost_of_revenue = found.get(\"Cost of Revenue\", 0) if found.get(\"Cost of Revenue\") != 'N/A' else 0\n",
    "            if revenue != 0 and cost_of_revenue != 0:\n",
    "                found[\"Gross Profit\"] = float(revenue) - float(cost_of_revenue)\n",
    "                print(f\"üìä Calculated Gross Profit: {found['Gross Profit']}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error in calculations: {e}\")\n",
    "    \n",
    "    # Print summary of what was found\n",
    "    found_count = sum(1 for v in found.values() if v != 'N/A')\n",
    "    print(f\"\\nüìà Extracted {found_count}/{len(TARGET_VARIANTS)} financial metrics\")\n",
    "    \n",
    "    return found\n",
    "\n",
    "def process_all_tickers():\n",
    "    cik_df = get_cik_mapping()\n",
    "    all_data = []\n",
    "\n",
    "    for ticker in TICKERS:\n",
    "        print(f\"\\nüìä Processing {ticker}\")\n",
    "        try:\n",
    "            cik, company = find_cik(ticker, cik_df)\n",
    "            if not cik:\n",
    "                print(f\"‚ùå No CIK for {ticker}\")\n",
    "                continue\n",
    "            content, form, date = download_latest_filing(cik)\n",
    "            path = save_filing(content, ticker, form, date)\n",
    "            data = parse_html_precise(path)\n",
    "\n",
    "            record = {\"Company\": company, \"Ticker\": ticker, \"Filing Date\": date, \"Filing Type\": form}\n",
    "            record.update(data)\n",
    "            all_data.append(record)\n",
    "            time.sleep(1)  # respectful delay\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error for {ticker}: {e}\")\n",
    "\n",
    "    if all_data:\n",
    "        df = pd.DataFrame(all_data)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        file = os.path.join(DOWNLOAD_DIR, f\"financials_{timestamp}.xlsx\")\n",
    "        df.to_excel(file, index=False)\n",
    "        print(f\"\\n‚úÖ All data saved to: {file}\")\n",
    "        \n",
    "        # Print comprehensive summary of what was found\n",
    "        print(\"\\nüìà Comprehensive Extraction Summary:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Group by category\n",
    "        categories = {\n",
    "            \"Balance Sheet - Assets\": [\"Current Assets\", \"Total Assets\", \"Goodwill\", \"Intangible Assets\", \n",
    "                                     \"Property, Plant, and Equipment (Net)\", \"Cash and Cash Equivalents\", \n",
    "                                     \"Accounts Receivable\", \"Inventory\"],\n",
    "            \"Balance Sheet - Liabilities\": [\"Current Liabilities\", \"Total Liabilities\", \"Short-Term Debt\", \n",
    "                                          \"Long-Term Debt\", \"Total Debt\", \"Accounts Payable\"],\n",
    "            \"Balance Sheet - Equity\": [\"Total Equity\", \"Treasury Stock\", \"Retained Earnings\", \"Preferred Stock\", \n",
    "                                     \"Common Shares Outstanding\", \"Book Value of Equity\", \n",
    "                                     \"Accumulated Other Comprehensive Income\"],\n",
    "            \"Income Statement\": [\"Revenue\", \"Net Income\", \"Operating Income (EBIT)\", \"Income Before Tax\", \n",
    "                               \"Income Tax Expense\", \"Research and Development Expense\", \"Cost of Revenue\", \n",
    "                               \"Gross Profit\", \"Comprehensive Income\"],\n",
    "            \"Cash Flow Statement\": [\"Operating Cash Flow\", \"Capital Expenditures (CapEx)\", \n",
    "                                  \"Depreciation & Amortization\", \"Free Cash Flow\"]\n",
    "        }\n",
    "        \n",
    "        for category, fields in categories.items():\n",
    "            print(f\"\\n{category}:\")\n",
    "            found_in_category = 0\n",
    "            for field in fields:\n",
    "                if field in TARGET_VARIANTS:\n",
    "                    found_count = sum(1 for row in all_data if row.get(field) != 'N/A')\n",
    "                    status = \"‚úÖ\" if found_count > 0 else \"‚ùå\"\n",
    "                    print(f\"  {status} {field}: {found_count}/{len(all_data)} companies\")\n",
    "                    if found_count > 0:\n",
    "                        found_in_category += 1\n",
    "            print(f\"  üìä Category Success: {found_in_category}/{len(fields)} fields found\")\n",
    "        \n",
    "        # Overall statistics\n",
    "        total_possible = len(TARGET_VARIANTS) * len(all_data)\n",
    "        total_found = sum(1 for row in all_data for key in TARGET_VARIANTS.keys() if row.get(key) != 'N/A')\n",
    "        success_rate = (total_found / total_possible) * 100\n",
    "        print(f\"\\nüéØ Overall Success Rate: {success_rate:.1f}% ({total_found}/{total_possible} data points)\")\n",
    "        \n",
    "        # Show companies with most/least data\n",
    "        company_scores = []\n",
    "        for row in all_data:\n",
    "            found_count = sum(1 for key in TARGET_VARIANTS.keys() if row.get(key) != 'N/A')\n",
    "            company_scores.append((row['Company'], found_count))\n",
    "        \n",
    "        company_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        print(f\"\\nüèÜ Data Coverage by Company:\")\n",
    "        for company, count in company_scores:\n",
    "            percentage = (count / len(TARGET_VARIANTS)) * 100\n",
    "            print(f\"  {company}: {count}/{len(TARGET_VARIANTS)} ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(\"=\" * 50)\n",
    "    else:\n",
    "        print(\"‚ùå No data extracted\")\n",
    "\n",
    "# === Append to Excel Master Sheet ===\n",
    "def append_to_master_excel(new_data, output_file):\n",
    "    new_df = pd.DataFrame(new_data)\n",
    "    if os.path.exists(output_file):\n",
    "        existing_df = pd.read_excel(output_file)\n",
    "        combined_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "    else:\n",
    "        combined_df = new_df\n",
    "    combined_df.to_excel(output_file, index=False)\n",
    "    print(f\"\\n‚úÖ Data appended to: {output_file}\")\n",
    "\n",
    "# === Processing Logic ===\n",
    "def process_all_tickers():\n",
    "    cik_df = get_cik_mapping()\n",
    "    all_data = []\n",
    "\n",
    "    for ticker in TICKERS:\n",
    "        print(f\"\\nüìä Processing {ticker}\")\n",
    "        try:\n",
    "            cik, company = find_cik(ticker, cik_df)\n",
    "            if not cik:\n",
    "                continue\n",
    "            content, form, date = download_latest_filing(cik)\n",
    "            path = save_filing(content, ticker, form, date)\n",
    "            data = parse_html_precise(path)\n",
    "\n",
    "            record = {\"Company\": company, \"Ticker\": ticker, \"Filing Date\": date, \"Filing Type\": form}\n",
    "            record.update(data)\n",
    "            all_data.append(record)\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error for {ticker}: {e}\")\n",
    "\n",
    "    if all_data:\n",
    "        append_to_master_excel(all_data, OUTPUT_FILE)\n",
    "\n",
    "# === MAIN ===\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Starting financial data extraction\")\n",
    "    process_all_tickers()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantproenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
